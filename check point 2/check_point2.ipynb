{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing, Analysis and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Read the data\n",
    "train_data = pd.read_csv(\"/Users/neehanthreddym/Desktop/AI/Project/check point 2/data/train.csv\")\n",
    "test_data = pd.read_csv(\"/Users/neehanthreddym/Desktop/AI/Project/check point 2/data/test.csv\")\n",
    "\n",
    "# Separating categorical and numerical features\n",
    "categorical_features = []\n",
    "threshold = 20\n",
    "for each in train_data.columns:\n",
    "    if train_data[each].nunique() < threshold:\n",
    "        categorical_features.append(each)\n",
    "\n",
    "numerical_features = []\n",
    "for each in train_data.columns:\n",
    "    if each not in categorical_features:\n",
    "        numerical_features.append(each)\n",
    "\n",
    "# Handling Missing Values and Feature Engineering\n",
    "alldata = pd.concat([train_data,test_data],axis=0,sort=False)\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "info_count = pd.DataFrame(alldata.isnull().sum(),columns=['Count of NaN'])\n",
    "dtype = pd.DataFrame(alldata.dtypes,columns=['DataTypes'])\n",
    "info = pd.concat([info_count,dtype],axis=1)\n",
    "\n",
    "# Filling 433 LotFrontage values. I will use linear interpolation to fill these NaN values.\n",
    "alldata['LotFrontage'].interpolate(method='linear',inplace=True)\n",
    "\n",
    "# Filling other NaNs\n",
    "for i in info.T:\n",
    "    if i == \"Id\" or i == \"SalePrice\" or i == \"LotFrontage\":\n",
    "        continue\n",
    "    else:\n",
    "        if (info.T[i][0] == 0):\n",
    "            continue\n",
    "        elif (info.T[i][0] < 400):\n",
    "            alldata[i].fillna(alldata[i].value_counts().index[0], inplace = True)\n",
    "        else:\n",
    "            lbl_enc = LabelEncoder()\n",
    "            lbl_enc.fit(list(alldata[i].values))\n",
    "            alldata[i] = lbl_enc.transform(list(alldata[i].values))\n",
    "\n",
    "# Handling the categorical columns because we will be using regression models algorithms.\n",
    "list_ = [\"MSZoning\", \"Street\", \"LotShape\", \"LandContour\", \"Utilities\", \"LotConfig\",\n",
    "        \"LandSlope\", \"Neighborhood\", \"Condition1\", \"Condition2\", \"BldgType\", \"HouseStyle\",\n",
    "        \"RoofStyle\", \"RoofMatl\", \"Exterior1st\", \"Exterior2nd\",\n",
    "        \"MasVnrType\", \"ExterQual\", \"ExterCond\", \"Foundation\", \"BsmtQual\", \"BsmtCond\", \"BsmtExposure\",\n",
    "        \"BsmtFinType1\", \"BsmtFinType2\", \"Heating\", \"HeatingQC\", \"CentralAir\", \"Electrical\", \"KitchenQual\",\n",
    "        \"Functional\", \"GarageType\", \"GarageFinish\", \"GarageQual\", \"GarageCond\", \"PavedDrive\", \"SaleType\",\n",
    "        \"SaleCondition\"]\n",
    "\n",
    "for feature in list_:\n",
    "    alldata[feature]= alldata[feature].astype(\"category\")\n",
    "    alldata = pd.get_dummies(alldata, columns=[feature])\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "# Selecting few rows for the model for train easily\n",
    "train = alldata[0:1460]\n",
    "test = alldata[1460:2920]\n",
    "\n",
    "test = test.drop(\"SalePrice\", axis=1)\n",
    "\n",
    "# Define x(predictors) and y(target)\n",
    "X = train.drop([\"Id\", \"SalePrice\"], axis=1)\n",
    "y = np.log1p(train['SalePrice'])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1095, 275)\n",
      "y_train shape: (1095,)\n",
      "X_test shape: (365, 275)\n",
      "y_test shape: (365,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape:', X_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated RMSE: 0.1664 ± 0.0326 (LR)\n",
      "Cross-validated RMSE: 0.1555 ± 0.0304 (Ridge)\n",
      "Cross-validated RMSE: 0.2022 ± 0.0413 (Lasso)\n",
      "Cross-validated RMSE: 0.197 ± 0.0394 (ElasticNet)\n",
      "Cross-validated RMSE: 0.2324 ± 0.0129 (KNN)\n",
      "Cross-validated RMSE: 0.1499 ± 0.0129 (RF)\n",
      "Cross-validated RMSE: 0.211 ± 0.0151 (SVR)\n",
      "Cross-validated RMSE: 0.1339 ± 0.0111 (GBR)\n",
      "\n",
      "Best Model: GBR with RMSE: 0.1339\n"
     ]
    }
   ],
   "source": [
    "import preprocess2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# Defining the variables form preprocess\n",
    "test = preprocess2.test\n",
    "X_train = preprocess2.X_train\n",
    "X_test = preprocess2.X_test\n",
    "y_train = preprocess2.y_train\n",
    "y_test = preprocess2.y_test\n",
    "\n",
    "# Initialize K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Defining the models\n",
    "models = [('LR', LinearRegression()),\n",
    "          (\"Ridge\", Ridge()),\n",
    "          (\"Lasso\", Lasso()),\n",
    "          (\"ElasticNet\", ElasticNet()),\n",
    "          ('KNN', KNeighborsRegressor()),\n",
    "          ('RF', RandomForestRegressor()),\n",
    "          ('SVR', SVR()),\n",
    "          ('GBR', GradientBoostingRegressor())]\n",
    "\n",
    "\n",
    "# Cross-Validation for RMSE\n",
    "cv_results = []\n",
    "for name, regressor in models:\n",
    "    # Compute cross-validated RMSE\n",
    "    neg_mse_scores = cross_val_score(regressor, X_train, y_train, cv=kf, scoring='neg_mean_squared_error')\n",
    "    rmse_scores = np.sqrt(-neg_mse_scores)\n",
    "    mean_rmse = np.mean(rmse_scores)\n",
    "    std_rmse = np.std(rmse_scores)\n",
    "    cv_results.append((name, mean_rmse, std_rmse))\n",
    "    print(f\"Cross-validated RMSE: {round(mean_rmse, 4)} ± {round(std_rmse, 4)} ({name})\")\n",
    "\n",
    "# Select the best model based on lowest RMSE\n",
    "best_model_name, best_mean_rmse, _ = min(cv_results, key=lambda x: x[1])\n",
    "print(f\"\\nBest Model: {best_model_name} with RMSE: {round(best_mean_rmse, 4)}\")\n",
    "\n",
    "# Export predictions using the best model\n",
    "best_model = [model for name, model in models if name == best_model_name][0]\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Final predictions\n",
    "X_test = test.drop(columns=['Id'])\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Id': test['Id'],\n",
    "    'SalePrice': np.floor(np.exp(y_pred)).astype(int)\n",
    "})\n",
    "\n",
    "predictions_df.to_csv('/Users/neehanthreddym/Desktop/AI/Project/check point 2/Result/REG-03-CKPT2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "Optimized Test RMSE: 0.1311\n"
     ]
    }
   ],
   "source": [
    "import preprocess2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn import metrics\n",
    "\n",
    "# Defining the variables from preprocess\n",
    "test = preprocess2.test\n",
    "X_train = preprocess2.X_train\n",
    "X_test = preprocess2.X_test\n",
    "y_train = preprocess2.y_train\n",
    "y_test = preprocess2.y_test\n",
    "\n",
    "# Initialize K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Gradient Boosting Hyperparameter Tuning\n",
    "gbr = GradientBoostingRegressor(random_state=42)\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"learning_rate\": [0.05, 0.1, 0.2],\n",
    "    \"max_depth\": [3, 4, 5],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=gbr,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=kf,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model and parameters\n",
    "best_gbr = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "# Evaluate the optimized model on the validation set\n",
    "y_pred = best_gbr.predict(X_test)\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Optimized Test RMSE: {round(rmse, 4)}\")\n",
    "\n",
    "# Final predictions on the test dataset\n",
    "X_test_final = test.drop(columns=['Id'])\n",
    "y_pred_final = best_gbr.predict(X_test_final)\n",
    "\n",
    "# Save predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Id': test['Id'],\n",
    "    'SalePrice': np.floor(np.exp(y_pred_final)).astype(int)\n",
    "})\n",
    "\n",
    "predictions_df.to_csv('/Users/neehanthreddym/Desktop/AI/Project/check point 2/Result/REG-03-CKPT2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
